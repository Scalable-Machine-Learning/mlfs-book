{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16b7819",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#1EB182;\"> **Air Quality** </span><span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 04: Batch Inference</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "\n",
    "1. Download model and batch inference data\n",
    "2. Make predictions, generate PNG for forecast\n",
    "3. Store predictions in a monitoring feature group adn generate PNG for hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a84ee9",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb904bb-a8c4-45d7-b54e-6d24f689c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Read the API keys and configuration variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f430c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "import json\n",
    "from mlfs.airquality import util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a4265d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 11, 17, 17, 51, 49, 437772)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.datetime.now() - datetime.timedelta(0)\n",
    "tomorrow = today + datetime.timedelta(days = 1)\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e91e99d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> üì° Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a2c243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:51:49,586 INFO: Initializing external client\n",
      "2025-11-17 17:51:49,587 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-11-17 17:51:50,314 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:51:51,397 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1271977\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\", project=\"air_quality_prediction\")\n",
    "fs = project.get_feature_store() \n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "# location = json.loads(location_str)\n",
    "# country=location['country']\n",
    "# city=location['city']\n",
    "# street=location['street']\n",
    "\n",
    "sensor_secret_names = [\n",
    "    \"SENSOR_LOCATION_bankgatan_JSON\",\n",
    "    \"SENSOR_LOCATION_linakersvagen_JSON\",\n",
    "    \"SENSOR_LOCATION_trollebergsvagen_JSON\",\n",
    "]\n",
    "\n",
    "sensors = {}\n",
    "for name in sensor_secret_names:\n",
    "    data = json.loads(secrets.get_secret(name).value)\n",
    "    sensors[data[\"street\"]] = {\n",
    "        \"country\":   data[\"country\"],\n",
    "        \"city\":      data[\"city\"],\n",
    "        \"street\":    data[\"street\"],\n",
    "        \"latitude\":  data[\"latitude\"],\n",
    "        \"longitude\": data[\"longitude\"],\n",
    "        \"aqicn_url\": data[\"aqicn_url\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb1c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.97s) \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=1\n",
    ")\n",
    "\n",
    "air_quality_df_full = air_quality_fg.read()\n",
    "streets_sorted = sorted(air_quality_df_full['street'].dropna().unique().tolist())\n",
    "street_encoder = LabelEncoder().fit(streets_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cead441",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">ü™ù Download the model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d70a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:52:00,373 INFO: Initializing for batch retrieval of feature vectors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e012c31aeff24922b90cee0e04698045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/171014 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14728a0a4304d218ca8ff7e2132bf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/111397 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab6d5497a84414eb0e0e6cf381573a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/77018 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98017474a86647d1ad146306be4e6bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/108093 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 4 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e75492353c34204950dfdc7e7b564c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/19961 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 5 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "\n",
    "retrieved_model = mr.get_model(\n",
    "    name=\"air_quality_xgboost_model\",\n",
    "    version=2,\n",
    ")\n",
    "\n",
    "fv = retrieved_model.get_feature_view()\n",
    "\n",
    "# Download the saved model artifacts to a local directory\n",
    "saved_model_dir = retrieved_model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6cf6c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=&#x27;8.042732E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=&#x27;8.042732E0&#x27;, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=[&#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;float&#x27;, &#x27;int&#x27;],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score='8.042732E0', booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None,\n",
       "             feature_types=['float', 'float', 'float', 'float', 'int'],\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the XGBoost regressor model and label encoder from the saved model directory\n",
    "# retrieved_xgboost_model = joblib.load(saved_model_dir + \"/xgboost_regressor.pkl\")\n",
    "retrieved_xgboost_model = XGBRegressor()\n",
    "\n",
    "retrieved_xgboost_model.load_model(saved_model_dir + \"/model.json\")\n",
    "\n",
    "# Displaying the retrieved XGBoost regressor model\n",
    "retrieved_xgboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad941a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚ú® Get Weather Forecast Features with Feature View   </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e4491",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü§ñ Making the predictions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebeaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x137d99120>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name='aq_predictions',\n",
    "    description='Air Quality prediction monitoring',\n",
    "    version=1,\n",
    "    primary_key=['city','street','date','days_before_forecast_day'],\n",
    "    event_time=\"date\",\n",
    ")\n",
    "\n",
    "monitor_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb9f38",
   "metadata": {},
   "outputs": [],
   "source": "all_preds_for_city = []  \n\nfor street, meta in sensors.items():\n\n    batch_data = weather_fg.filter(weather_fg.date >= today).read().copy()\n    if batch_data.empty:\n        print(f\"[WARN] No weather rows for {street}; skipping.\")\n        continue\n\n    batch_data['country'] = meta['country']\n    batch_data['city']    = meta['city']\n    batch_data['street']  = meta['street']\n\n    batch_data['date'] = pd.to_datetime(batch_data['date']).dt.tz_localize(None)\n    batch_data = batch_data.sort_values('date').reset_index(drop=True)\n    batch_data['days_before_forecast_day'] = ((batch_data['date'] - today).dt.days + 1)\n    batch_data = batch_data.query('days_before_forecast_day >= 1')\n\n    batch_data['street_encode'] = street_encoder.transform(batch_data['street']).astype('float32')\n\n    hist_aq = air_quality_fg.filter(\n        (air_quality_fg.street == street) & \n        (air_quality_fg.date < today)\n    ).read()\n    \n    if hist_aq.empty:\n        print(f\"[WARN] No historical air quality for {street}; skipping.\")\n        continue\n    \n    hist_aq['date'] = pd.to_datetime(hist_aq['date']).dt.tz_localize(None)\n    hist_aq = hist_aq.sort_values('date').tail(3).reset_index(drop=True)\n    \n    if len(hist_aq) < 3:\n        print(f\"[WARN] Less than 3 days of history for {street}; skipping.\")\n        continue\n\n    predictions = []\n    \n    for idx, row in batch_data.iterrows():\n        day_num = row['days_before_forecast_day']\n        \n        if day_num == 1:\n            lag_1 = hist_aq.iloc[-1]['pm25']\n            lag_2 = hist_aq.iloc[-2]['pm25']\n            lag_3 = hist_aq.iloc[-3]['pm25']\n        elif day_num == 2:\n            lag_1 = predictions[0]\n            lag_2 = hist_aq.iloc[-1]['pm25']\n            lag_3 = hist_aq.iloc[-2]['pm25']\n        elif day_num == 3:\n            lag_1 = predictions[1]\n            lag_2 = predictions[0]\n            lag_3 = hist_aq.iloc[-1]['pm25']\n        else:\n            lag_1 = predictions[day_num - 2]\n            lag_2 = predictions[day_num - 3]\n            lag_3 = predictions[day_num - 4]\n        \n        features = [\n            row['temperature_2m_mean'],\n            row['precipitation_sum'],\n            row['wind_speed_10m_max'],\n            row['wind_direction_10m_dominant'],\n            row['street_encode'],\n            lag_1,\n            lag_2,\n            lag_3\n        ]\n        \n        pred = retrieved_xgboost_model.predict([features])[0]\n        predictions.append(pred)\n\n    batch_data['predicted_pm25'] = predictions\n    batch_data['pm25_lag_1day'] = [predictions[i-1] if i > 0 else hist_aq.iloc[-1]['pm25'] for i in range(len(predictions))]\n    batch_data['pm25_lag_2day'] = [predictions[i-2] if i > 1 else (predictions[0] if i == 1 else hist_aq.iloc[-2]['pm25']) for i in range(len(predictions))]\n    batch_data['pm25_lag_3day'] = [predictions[i-3] if i > 2 else (predictions[i-1] if i == 2 else (predictions[0] if i == 1 else hist_aq.iloc[-3]['pm25'])) for i in range(len(predictions))]\n\n    monitor_fg.insert(batch_data.drop(columns=['street_encode']), wait=True)\n\n    all_preds_for_city.append(batch_data.drop(columns=['street_encode']))"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a52a3126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timedelta:\n",
      "0    2\n",
      "1    3\n",
      "2    4\n",
      "3    5\n",
      "4    6\n",
      "5    7\n",
      "6    8\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Timedelta:\")\n",
    "print((batch_data['date'] - today).dt.days + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e2b0a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ü§ñ Saving the predictions (for monitoring) to a Feature Group</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff10c12",
   "metadata": {},
   "source": [
    "### Create Forecast Graph\n",
    "Draw a graph of the predictions with dates as a PNG and save it to the github repo\n",
    "Show it on github pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c99085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "root_dir = str(Path().absolute())\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# this part is specific to me due to directory naming issues. \n",
    "def find_repo_root():\n",
    "    here = Path.cwd()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"docs\").exists():\n",
    "            return p\n",
    "    return here  \n",
    "\n",
    "project_root = find_repo_root()\n",
    "\n",
    "img_dir = project_root / \"docs\" / \"air-quality\" / \"assets\" / \"img\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "today_str = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "dataset_api = project.get_dataset_api()\n",
    "if not dataset_api.exists(\"Resources/airquality\"):\n",
    "    dataset_api.mkdir(\"Resources/airquality\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2c1b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (2.00s) \n",
      "bankgatan rows: 7 nans: 0 dates: 2025-11-18 00:00:00 ‚Üí 2025-11-24 00:00:00\n",
      "2025-11-17 18:02:00,124 WARNING: DeprecationWarning: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f056e6cb14f84f86a30b69d705e890d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_bankgata‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de664ef4ef0f40058293068e7796ad4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_bankgata‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin√•kersv√§gen rows: 7 nans: 0 dates: 2025-11-18 00:00:00 ‚Üí 2025-11-24 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6929691bc3ee40e28ab29212189fb437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_lin√•kers‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f7c58fd5454bee82bd0dfc9b2e6a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_lin√•kers‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trollebergsv√§gen rows: 7 nans: 0 dates: 2025-11-18 00:00:00 ‚Üí 2025-11-24 00:00:00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5177306ae584567bd59ab46e3e67f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_trollebe‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0853d542624fffa76871e0a4cc475c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading /Users/sebastian/Documents/KTH/Year 1/ID2223-SML/mlfs-book/docs/air-quality/assets/img/lund_trollebe‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are saved here: https://c.app.hopsworks.ai:443/p/1271977/settings/fb/path/Resources/airquality\n"
     ]
    }
   ],
   "source": [
    "city = next(iter(sensors.values()))['city']  # since all sensors are in the same city\n",
    "preds_1day_city = monitor_fg.filter(\n",
    "    (monitor_fg.city == city) &\n",
    "    (monitor_fg.days_before_forecast_day == 1)\n",
    ").read().copy()\n",
    "\n",
    "def _norm_dates(series):\n",
    "    s = pd.to_datetime(series, errors=\"coerce\")\n",
    "    try:\n",
    "        s = s.dt.tz_convert(None)   \n",
    "    except Exception:\n",
    "        pass\n",
    "    return s.dt.normalize()\n",
    "\n",
    "for street, meta in sensors.items():\n",
    "\n",
    "    preds_1day = preds_1day_city[preds_1day_city['street'] == street].copy()\n",
    "\n",
    "    outcomes = air_quality_df_full[\n",
    "        (air_quality_df_full['city'] == meta['city']) &\n",
    "        (air_quality_df_full['street'] == street)\n",
    "    ][['date', 'pm25']].copy()\n",
    "\n",
    "\n",
    "    try:\n",
    "        nday_df = next(df for df in all_preds_for_city if df['street'].iloc[0] == street)\n",
    "    except StopIteration:\n",
    "        print(f\"[WARN] No in-memory forecast DF found for street '{street}'. Skipping plots.\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    safe_city = str(meta['city']).replace(' ', '_').lower()\n",
    "    safe_street = str(street).replace(' ', '_').lower()\n",
    "\n",
    "    pred_file_path = str(img_dir / f\"{safe_city}_{safe_street}_pm25_forecast.png\")\n",
    "    hindcast_file_path = str(img_dir / f\"{safe_city}_{safe_street}_pm25_hindcast_1day.png\")\n",
    "\n",
    "\n",
    "    print(\n",
    "        street,\n",
    "        \"rows:\", len(nday_df),\n",
    "        \"nans:\", nday_df['predicted_pm25'].isna().sum() if 'predicted_pm25' in nday_df.columns else 'col-missing',\n",
    "        \"dates:\", nday_df['date'].min(), \"‚Üí\", nday_df['date'].max()\n",
    "    )\n",
    "    plt = util.plot_air_quality_forecast(meta['city'], street, nday_df, pred_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    if preds_1day.empty or outcomes.empty:\n",
    "        print(f\"[WARN] Empty preds_1day or outcomes for '{street}'. Skipping hindcast plot.\")\n",
    "    else:\n",
    "  \n",
    "        preds_1day['date'] = _norm_dates(preds_1day['date'])\n",
    "        outcomes['date']   = _norm_dates(outcomes['date'])\n",
    "\n",
    "        min_d, max_d = outcomes['date'].min(), outcomes['date'].max()\n",
    "        preds_1day = preds_1day[(preds_1day['date'] >= min_d) & (preds_1day['date'] <= max_d)].copy()\n",
    "\n",
    "        hindcast_df = (\n",
    "            preds_1day[['date', 'predicted_pm25']]\n",
    "            .merge(outcomes, on='date', how='inner')\n",
    "            .sort_values('date')\n",
    "        )\n",
    "\n",
    "        if hindcast_df.empty:\n",
    "            print(f\"[WARN] No overlapping dates for hindcast at '{street}'. Skipping hindcast plot.\")\n",
    "        else:\n",
    "            plt = util.plot_air_quality_forecast(\n",
    "                meta['city'], street, hindcast_df, hindcast=True, file_path=hindcast_file_path\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "    hops_dir = f\"Resources/airquality/{safe_city}_{safe_street}_{today_str}\"\n",
    "    dataset_api.upload(pred_file_path, hops_dir, overwrite=True)\n",
    "    if Path(hindcast_file_path).exists():\n",
    "        dataset_api.upload(hindcast_file_path, hops_dir, overwrite=True)\n",
    "\n",
    "print(f\"The images are saved here: {project.get_url()}/settings/fb/path/Resources/airquality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb1552",
   "metadata": {},
   "source": [
    "### Plot the Hindcast comparing predicted with forecasted values (1-day prior forecast)\n",
    "\n",
    "__This graph will be empty to begin with - this is normal.__\n",
    "\n",
    "After a few days of predictions and observations, you will get data points in this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf88a81-5a3e-43d7-a8a5-177e5c2b5387",
   "metadata": {},
   "source": [
    "### Upload the prediction and hindcast dashboards (png files) to Hopsworks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29eb549",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1d89e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}